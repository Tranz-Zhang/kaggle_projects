{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Competition Description\n",
    "The sinking of the RMS Titanic is one of the most infamous shipwrecks in history. On April 15, 1912, during her maiden voyage, the Titanic sank after colliding with an iceberg, killing 1502 out of 2224 passengers and crew. This sensational tragedy shocked the international community and led to better safety regulations for ships.\n",
    "\n",
    "One of the reasons that the shipwreck led to such loss of life was that there were not enough lifeboats for the passengers and crew. Although there was some element of luck involved in surviving the sinking, some groups of people were more likely to survive than others, such as women, children, and the upper-class.\n",
    "\n",
    "In this challenge, we ask you to complete the analysis of what sorts of people were likely to survive. In particular, we ask you to apply the tools of machine learning to predict which passengers survived the tragedy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv(\"train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 抽离Label项：Survived\n",
    "y_train = train_data[\"Survived\"].copy()\n",
    "x_train = train_data.drop(columns=[\"Survived\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 数据预处理 num pipeline\n",
    "from sklearn.base import BaseEstimator\n",
    "class NumberPreprocesser(BaseEstimator):\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    def transform(self, X, y=None):\n",
    "        # 数字项：Pclass, Age, SibSp, Parch, Fare\n",
    "        x_num = X[[\"Pclass\", \"Age\", \"Fare\", \"Sex\"]].copy()\n",
    "        # 调整船舱级别数值，越高级数字越高\n",
    "        x_num[\"Pclass\"].replace({1:3, 3:1}, inplace=True)\n",
    "        # Sex 分类转换为数字项\n",
    "        x_num[\"Sex\"].replace({\"male\":0, \"female\":1}, inplace=True)\n",
    "        # 添加计算属性\n",
    "        x_num[\"Parch_b\"] = X[\"Parch\"] > 0\n",
    "        x_num[\"SibSp_b\"] = X[\"SibSp\"] > 0\n",
    "        # x_train_num[\"single_dog\"] = (X[\"Parch\"] == 0) & (X[\"SibSp\"] == 0)\n",
    "        x_num[\"Has_family\"] = (X[\"Parch\"] > 0) | (X[\"SibSp\"] > 0)\n",
    "        return x_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import Imputer, StandardScaler\n",
    "num_pipeline = Pipeline([\n",
    "    (\"NumberPreprecess\", NumberPreprocesser()),\n",
    "    (\"Imputer\", Imputer(strategy=\"median\")),\n",
    "#     (\"SandardScaler\", StandardScaler()), # 考虑这里加上Scaler\n",
    "])\n",
    "num_attribs = [\"Pclass\", \"Age\", \"Fare\", \"Sex\", \"Parch_b\", \"SibSp_b\", \"Has_family\"]\n",
    "# x_train_num = num_pipeline.fit_transform(x_train)\n",
    "# x_num_df = pd.DataFrame(x_train_num, columns=num_attribs)\n",
    "# x_num_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 分类数据预处理\n",
    "class CagetoryPreprosser(BaseEstimator):\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    def transform(self, X, y=None):\n",
    "        # process Embarked category\n",
    "        embarked = X[[\"Embarked\"]].copy()\n",
    "        embarked = pd.get_dummies(embarked)\n",
    "        # process Cabin\n",
    "        cabin = x_train[\"Cabin\"].copy()\n",
    "        cabin.replace(to_replace=\"A.*\", value=\"A\", regex=True, inplace=True)\n",
    "        cabin.replace(to_replace=\"B.*\", value=\"B\", regex=True, inplace=True)\n",
    "        cabin.replace(to_replace=\"C.*\", value=\"C\", regex=True, inplace=True)\n",
    "        cabin.replace(to_replace=\"D.*\", value=\"D\", regex=True, inplace=True)\n",
    "        cabin.replace(to_replace=\"E.*\", value=\"E\", regex=True, inplace=True)\n",
    "        cabin.replace(to_replace=\"F.*\", value=\"F\", regex=True, inplace=True)\n",
    "        cabin.replace(to_replace=\"G.*\", value=\"G\", regex=True, inplace=True)\n",
    "        cabin.replace(to_replace=\"T.*\", value=\"T\", regex=True, inplace=True)\n",
    "        cabin = pd.get_dummies(cabin)\n",
    "#         return np.hstack((embarked.values, cabin.values))\n",
    "        return embarked.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_pipeline = Pipeline([\n",
    "    (\"CagetoryPreprosser\", CagetoryPreprosser()),\n",
    "])\n",
    "\n",
    "cat_attribs = [\"Embarked_C\",\"Embarked_Q\",\"Embarked_S\"]\n",
    "# x_train_cat = cat_pipeline.fit_transform(x_train)\n",
    "# x_cat_df = pd.DataFrame(x_train_cat, columns = cat_attribs)\n",
    "# x_cat_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 10 columns):\n",
      "Pclass        891 non-null float64\n",
      "Age           891 non-null float64\n",
      "Fare          891 non-null float64\n",
      "Sex           891 non-null float64\n",
      "Parch_b       891 non-null float64\n",
      "SibSp_b       891 non-null float64\n",
      "Has_family    891 non-null float64\n",
      "Embarked_C    891 non-null float64\n",
      "Embarked_Q    891 non-null float64\n",
      "Embarked_S    891 non-null float64\n",
      "dtypes: float64(10)\n",
      "memory usage: 69.7 KB\n"
     ]
    }
   ],
   "source": [
    "# 数据预处理 Full  pipeline\n",
    "from sklearn.pipeline import FeatureUnion\n",
    "full_pipeline = FeatureUnion(transformer_list=[\n",
    "    (\"num_pipeline\", num_pipeline),\n",
    "    (\"cat_pipeline\", cat_pipeline),\n",
    "])\n",
    "x_train_prepared = full_pipeline.fit_transform(x_train)\n",
    "full_attribs = num_attribs + cat_attribs\n",
    "x_prepared_df = pd.DataFrame(x_train_prepared, columns = full_attribs)\n",
    "x_prepared_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Age</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Parch_b</th>\n",
       "      <th>SibSp_b</th>\n",
       "      <th>Has_family</th>\n",
       "      <th>Embarked_C</th>\n",
       "      <th>Embarked_Q</th>\n",
       "      <th>Embarked_S</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Pclass   Age     Fare  Sex  Parch_b  SibSp_b  Has_family  Embarked_C  \\\n",
       "0     1.0  22.0   7.2500  0.0      0.0      1.0         1.0         0.0   \n",
       "1     3.0  38.0  71.2833  1.0      0.0      1.0         1.0         1.0   \n",
       "2     1.0  26.0   7.9250  1.0      0.0      0.0         0.0         0.0   \n",
       "3     3.0  35.0  53.1000  1.0      0.0      1.0         1.0         0.0   \n",
       "4     1.0  35.0   8.0500  0.0      0.0      0.0         0.0         0.0   \n",
       "\n",
       "   Embarked_Q  Embarked_S  \n",
       "0         0.0         1.0  \n",
       "1         0.0         0.0  \n",
       "2         0.0         1.0  \n",
       "3         0.0         1.0  \n",
       "4         0.0         1.0  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_prepared_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Try Different Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross Validation\n",
    "from sklearn.model_selection import cross_val_predict, cross_val_score\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score, confusion_matrix\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision: 0.42\n",
      "recall: 0.5526315789473685\n",
      "f1: 0.4772727272727273\n",
      "cross_val_score: [0.43097643 0.68350168 0.4040404 ]\n"
     ]
    }
   ],
   "source": [
    "# SGDClassifier\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "sgd_clf = SGDClassifier()\n",
    "sgd_clf.fit(x_train_prepared, y_train)\n",
    "\n",
    "y_train_pred = cross_val_predict(sgd_clf, x_train_prepared, y_train, cv=3)\n",
    "confusion_matrix(y_train, y_train_pred)\n",
    "\n",
    "print(\"precision:\", precision_score(y_train, y_train_pred))\n",
    "print(\"recall:\", recall_score(y_train, y_train_pred))\n",
    "print(\"f1:\", f1_score(y_train, y_train_pred))\n",
    "\n",
    "cv_score = cross_val_score(sgd_clf, x_train_prepared, y_train, cv=3, scoring=\"accuracy\")\n",
    "print(\"cross_val_score:\", cv_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision: 0.7412140575079872\n",
      "recall: 0.6783625730994152\n",
      "f1: 0.7083969465648854\n",
      "cross_val_score: [0.77104377 0.79124579 0.79461279]\n"
     ]
    }
   ],
   "source": [
    "# RandomForestTree\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "forest_clf = RandomForestClassifier(random_state=42)\n",
    "forest_clf.fit(x_train_prepared, y_train)\n",
    "\n",
    "y_train_pred = cross_val_predict(forest_clf, x_train_prepared, y_train, cv=3)\n",
    "confusion_matrix(y_train, y_train_pred)\n",
    "\n",
    "print(\"precision:\", precision_score(y_train, y_train_pred))\n",
    "print(\"recall:\", recall_score(y_train, y_train_pred))\n",
    "print(\"f1:\", f1_score(y_train, y_train_pred))\n",
    "\n",
    "cv_score = cross_val_score(forest_clf, x_train_prepared, y_train, cv=3, scoring=\"accuracy\")\n",
    "print(\"cross_val_score:\", cv_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Randomize Search CV\n",
    "# from sklearn.model_selection import RandomizedSearchCV\n",
    "# from scipy.stats import randint as sp_randint\n",
    "\n",
    "# param_dict = {\n",
    "#     \"n_estimators\": np.arange(1, 100, 3),\n",
    "#     \"max_features\": np.arange(1, len(full_attribs) + 1, 1),\n",
    "#     \"bootstrap\": [True, False],\n",
    "# }\n",
    "# randomized_search = RandomizedSearchCV(forest_clf, param_distributions=param_dict, n_iter=10, cv=3, scoring=\"f1\", return_train_score=True)\n",
    "# randomized_search.fit(x_train_prepared, y_train)\n",
    "# randomized_search.cv_results_\n",
    "# for mean_score, params in zip(cvres['mean_test_score'], cvres['params']):\n",
    "#     print(mean_score, params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7423924066801599 {'bootstrap': True, 'max_features': 10, 'n_estimators': 10000}\n",
      "0.7412881634234504 {'bootstrap': True, 'max_features': 10, 'n_estimators': 3000}\n",
      "0.7405567905811394 {'bootstrap': True, 'max_features': 10, 'n_estimators': 1000}\n",
      "0.7384988132862503 {'bootstrap': True, 'max_features': 8, 'n_estimators': 1000}\n",
      "0.7383937868835224 {'bootstrap': True, 'max_features': 9, 'n_estimators': 1000}\n",
      "0.7373981651267787 {'bootstrap': True, 'max_features': 8, 'n_estimators': 3000}\n",
      "0.7366895704150607 {'bootstrap': True, 'max_features': 9, 'n_estimators': 3000}\n",
      "0.7365204515244805 {'bootstrap': True, 'max_features': 9, 'n_estimators': 10000}\n",
      "0.7363172070565733 {'bootstrap': True, 'max_features': 8, 'n_estimators': 10000}\n",
      "0.7357852778433378 {'bootstrap': True, 'max_features': 9, 'n_estimators': 300}\n",
      "0.735575485799701 {'bootstrap': True, 'max_features': 10, 'n_estimators': 300}\n",
      "0.7288692508015012 {'bootstrap': True, 'max_features': 8, 'n_estimators': 100}\n",
      "0.7285513131101365 {'bootstrap': True, 'max_features': 8, 'n_estimators': 300}\n",
      "0.7282852011910079 {'bootstrap': True, 'max_features': 10, 'n_estimators': 100}\n",
      "0.7244081850594569 {'bootstrap': True, 'max_features': 9, 'n_estimators': 100}\n"
     ]
    }
   ],
   "source": [
    "# GridSearchCV\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "param_grid = [\n",
    "    {\n",
    "    \"n_estimators\": [100, 300, 1000, 3000, 10000],\n",
    "    \"max_features\": [8, 9, 10],\n",
    "    \"bootstrap\": [True],\n",
    "    },\n",
    "]\n",
    "grid_search = GridSearchCV(forest_clf, param_grid, cv=3, scoring=\"f1\", return_train_score=True, n_jobs=3)\n",
    "grid_search.fit(x_train_prepared, y_train)\n",
    "cvres = grid_search.cv_results_\n",
    "for mean_score, params in sorted(zip(cvres['mean_test_score'], cvres['params']), key=lambda x: x[0], reverse=True):\n",
    "    print(mean_score, params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.3063945858677551, 'Sex'),\n",
       " (0.263049328444382, 'Fare'),\n",
       " (0.2462522455919866, 'Age'),\n",
       " (0.11233433102644412, 'Pclass'),\n",
       " (0.015971489372220656, 'Parch_b'),\n",
       " (0.01549810260578968, 'Embarked_S'),\n",
       " (0.013101673398162825, 'SibSp_b'),\n",
       " (0.010880133909198276, 'Embarked_C'),\n",
       " (0.009932244688338632, 'Has_family'),\n",
       " (0.006585865095724557, 'Embarked_Q')]"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_importances = grid_search.best_estimator_.feature_importances_\n",
    "sorted(zip(feature_importances, full_attribs), reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/usr/local/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/usr/local/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7240640813654924 {'activation': 'logistic', 'alpha': 0.1, 'hidden_layer_sizes': 3, 'learning_rate': 'constant'}\n",
      "0.7209210751583631 {'activation': 'relu', 'alpha': 0.1, 'hidden_layer_sizes': 30, 'learning_rate': 'adaptive'}\n",
      "0.7206441119063111 {'activation': 'relu', 'alpha': 0.03, 'hidden_layer_sizes': 10, 'learning_rate': 'constant'}\n",
      "0.7205534764810477 {'activation': 'relu', 'alpha': 0.03, 'hidden_layer_sizes': 10, 'learning_rate': 'adaptive'}\n",
      "0.7196887731249583 {'activation': 'logistic', 'alpha': 1.0, 'hidden_layer_sizes': 30, 'learning_rate': 'invscaling'}\n",
      "0.7195849695849694 {'activation': 'relu', 'alpha': 0.1, 'hidden_layer_sizes': 3, 'learning_rate': 'adaptive'}\n",
      "0.7188497880846091 {'activation': 'logistic', 'alpha': 0.3, 'hidden_layer_sizes': 30, 'learning_rate': 'invscaling'}\n",
      "0.7175294315336967 {'activation': 'relu', 'alpha': 0.03, 'hidden_layer_sizes': 3, 'learning_rate': 'adaptive'}\n",
      "0.7168215173778517 {'activation': 'logistic', 'alpha': 0.03, 'hidden_layer_sizes': 30, 'learning_rate': 'invscaling'}\n",
      "0.7166581518540711 {'activation': 'relu', 'alpha': 0.03, 'hidden_layer_sizes': 30, 'learning_rate': 'constant'}\n",
      "0.715813564778394 {'activation': 'relu', 'alpha': 0.03, 'hidden_layer_sizes': 30, 'learning_rate': 'adaptive'}\n",
      "0.7152247599495306 {'activation': 'logistic', 'alpha': 1.0, 'hidden_layer_sizes': 10, 'learning_rate': 'adaptive'}\n",
      "0.714718336520489 {'activation': 'relu', 'alpha': 0.1, 'hidden_layer_sizes': 10, 'learning_rate': 'constant'}\n",
      "0.7144352250077688 {'activation': 'relu', 'alpha': 1.0, 'hidden_layer_sizes': 30, 'learning_rate': 'invscaling'}\n",
      "0.714211160372435 {'activation': 'relu', 'alpha': 0.1, 'hidden_layer_sizes': 3, 'learning_rate': 'constant'}\n",
      "0.7140405625958778 {'activation': 'relu', 'alpha': 0.1, 'hidden_layer_sizes': 30, 'learning_rate': 'invscaling'}\n",
      "0.7136815472480389 {'activation': 'relu', 'alpha': 0.3, 'hidden_layer_sizes': 3, 'learning_rate': 'constant'}\n",
      "0.7134562062164823 {'activation': 'logistic', 'alpha': 0.3, 'hidden_layer_sizes': 30, 'learning_rate': 'adaptive'}\n",
      "0.7132271166052253 {'activation': 'relu', 'alpha': 1.0, 'hidden_layer_sizes': 3, 'learning_rate': 'invscaling'}\n",
      "0.7131813974555911 {'activation': 'logistic', 'alpha': 0.3, 'hidden_layer_sizes': 3, 'learning_rate': 'constant'}\n",
      "0.7129886025846857 {'activation': 'relu', 'alpha': 0.3, 'hidden_layer_sizes': 10, 'learning_rate': 'adaptive'}\n",
      "0.7128450359363577 {'activation': 'logistic', 'alpha': 0.1, 'hidden_layer_sizes': 10, 'learning_rate': 'constant'}\n",
      "0.7123342962734133 {'activation': 'logistic', 'alpha': 1.0, 'hidden_layer_sizes': 30, 'learning_rate': 'constant'}\n",
      "0.7117724867724868 {'activation': 'logistic', 'alpha': 0.3, 'hidden_layer_sizes': 30, 'learning_rate': 'constant'}\n",
      "0.7113576327580502 {'activation': 'relu', 'alpha': 1.0, 'hidden_layer_sizes': 10, 'learning_rate': 'invscaling'}\n",
      "0.7105779357556609 {'activation': 'logistic', 'alpha': 0.03, 'hidden_layer_sizes': 3, 'learning_rate': 'invscaling'}\n",
      "0.7102930012605949 {'activation': 'relu', 'alpha': 0.3, 'hidden_layer_sizes': 30, 'learning_rate': 'invscaling'}\n",
      "0.7097419307403867 {'activation': 'logistic', 'alpha': 0.3, 'hidden_layer_sizes': 3, 'learning_rate': 'adaptive'}\n",
      "0.7096731167383341 {'activation': 'relu', 'alpha': 1.0, 'hidden_layer_sizes': 3, 'learning_rate': 'adaptive'}\n",
      "0.7089682564590765 {'activation': 'relu', 'alpha': 0.3, 'hidden_layer_sizes': 30, 'learning_rate': 'adaptive'}\n",
      "0.7087864703772391 {'activation': 'relu', 'alpha': 0.3, 'hidden_layer_sizes': 10, 'learning_rate': 'constant'}\n",
      "0.708639839102589 {'activation': 'relu', 'alpha': 0.03, 'hidden_layer_sizes': 30, 'learning_rate': 'invscaling'}\n",
      "0.7074334380013988 {'activation': 'relu', 'alpha': 0.1, 'hidden_layer_sizes': 10, 'learning_rate': 'adaptive'}\n",
      "0.7065716251648372 {'activation': 'relu', 'alpha': 0.1, 'hidden_layer_sizes': 30, 'learning_rate': 'constant'}\n",
      "0.7059674745755117 {'activation': 'logistic', 'alpha': 1.0, 'hidden_layer_sizes': 3, 'learning_rate': 'invscaling'}\n",
      "0.7057896366632208 {'activation': 'logistic', 'alpha': 0.03, 'hidden_layer_sizes': 10, 'learning_rate': 'constant'}\n",
      "0.7057609341515081 {'activation': 'relu', 'alpha': 0.3, 'hidden_layer_sizes': 30, 'learning_rate': 'constant'}\n",
      "0.7047283539322243 {'activation': 'relu', 'alpha': 1.0, 'hidden_layer_sizes': 10, 'learning_rate': 'constant'}\n",
      "0.7044445661665337 {'activation': 'relu', 'alpha': 1.0, 'hidden_layer_sizes': 30, 'learning_rate': 'adaptive'}\n",
      "0.7043331022457511 {'activation': 'logistic', 'alpha': 0.3, 'hidden_layer_sizes': 10, 'learning_rate': 'constant'}\n",
      "0.7028083450687215 {'activation': 'logistic', 'alpha': 0.03, 'hidden_layer_sizes': 3, 'learning_rate': 'adaptive'}\n",
      "0.702653997378768 {'activation': 'logistic', 'alpha': 1.0, 'hidden_layer_sizes': 30, 'learning_rate': 'adaptive'}\n",
      "0.702512281654109 {'activation': 'relu', 'alpha': 0.3, 'hidden_layer_sizes': 10, 'learning_rate': 'invscaling'}\n",
      "0.7021387819341783 {'activation': 'relu', 'alpha': 1.0, 'hidden_layer_sizes': 10, 'learning_rate': 'adaptive'}\n",
      "0.7000707092724329 {'activation': 'logistic', 'alpha': 1.0, 'hidden_layer_sizes': 3, 'learning_rate': 'adaptive'}\n",
      "0.6992544628231532 {'activation': 'logistic', 'alpha': 0.3, 'hidden_layer_sizes': 10, 'learning_rate': 'invscaling'}\n",
      "0.6985760532801768 {'activation': 'logistic', 'alpha': 0.03, 'hidden_layer_sizes': 10, 'learning_rate': 'invscaling'}\n",
      "0.6984879132017645 {'activation': 'relu', 'alpha': 1.0, 'hidden_layer_sizes': 30, 'learning_rate': 'constant'}\n",
      "0.6973228927602214 {'activation': 'relu', 'alpha': 1.0, 'hidden_layer_sizes': 3, 'learning_rate': 'constant'}\n",
      "0.6957764124139735 {'activation': 'logistic', 'alpha': 0.1, 'hidden_layer_sizes': 10, 'learning_rate': 'adaptive'}\n",
      "0.6950171236760336 {'activation': 'relu', 'alpha': 0.1, 'hidden_layer_sizes': 3, 'learning_rate': 'invscaling'}\n",
      "0.6949748062578406 {'activation': 'logistic', 'alpha': 1.0, 'hidden_layer_sizes': 3, 'learning_rate': 'constant'}\n",
      "0.6942959020961865 {'activation': 'logistic', 'alpha': 0.1, 'hidden_layer_sizes': 30, 'learning_rate': 'constant'}\n",
      "0.6935155122655122 {'activation': 'logistic', 'alpha': 0.3, 'hidden_layer_sizes': 10, 'learning_rate': 'adaptive'}\n",
      "0.6934077570935148 {'activation': 'logistic', 'alpha': 0.03, 'hidden_layer_sizes': 3, 'learning_rate': 'constant'}\n",
      "0.6932744810924887 {'activation': 'logistic', 'alpha': 0.1, 'hidden_layer_sizes': 10, 'learning_rate': 'invscaling'}\n",
      "0.6930723616880381 {'activation': 'logistic', 'alpha': 0.03, 'hidden_layer_sizes': 30, 'learning_rate': 'adaptive'}\n",
      "0.690864258754167 {'activation': 'logistic', 'alpha': 1.0, 'hidden_layer_sizes': 10, 'learning_rate': 'constant'}\n",
      "0.6899454245510782 {'activation': 'logistic', 'alpha': 0.03, 'hidden_layer_sizes': 10, 'learning_rate': 'adaptive'}\n",
      "0.6889518529553074 {'activation': 'relu', 'alpha': 0.3, 'hidden_layer_sizes': 3, 'learning_rate': 'invscaling'}\n",
      "0.6888219866098483 {'activation': 'logistic', 'alpha': 0.1, 'hidden_layer_sizes': 3, 'learning_rate': 'adaptive'}\n",
      "0.6849565286751216 {'activation': 'logistic', 'alpha': 0.1, 'hidden_layer_sizes': 3, 'learning_rate': 'invscaling'}\n",
      "0.6821348801546822 {'activation': 'logistic', 'alpha': 0.3, 'hidden_layer_sizes': 3, 'learning_rate': 'invscaling'}\n",
      "0.6816274271479337 {'activation': 'logistic', 'alpha': 0.1, 'hidden_layer_sizes': 30, 'learning_rate': 'invscaling'}\n",
      "0.6791165818200238 {'activation': 'logistic', 'alpha': 0.03, 'hidden_layer_sizes': 30, 'learning_rate': 'constant'}\n",
      "0.6777807558295365 {'activation': 'logistic', 'alpha': 0.1, 'hidden_layer_sizes': 30, 'learning_rate': 'adaptive'}\n",
      "0.6735632937678974 {'activation': 'logistic', 'alpha': 1.0, 'hidden_layer_sizes': 10, 'learning_rate': 'invscaling'}\n",
      "0.6677153896331978 {'activation': 'relu', 'alpha': 0.1, 'hidden_layer_sizes': 10, 'learning_rate': 'invscaling'}\n",
      "0.6182577021228062 {'activation': 'relu', 'alpha': 0.03, 'hidden_layer_sizes': 10, 'learning_rate': 'invscaling'}\n",
      "0.4781257027953063 {'activation': 'relu', 'alpha': 0.03, 'hidden_layer_sizes': 3, 'learning_rate': 'invscaling'}\n",
      "0.4744354110207769 {'activation': 'relu', 'alpha': 0.3, 'hidden_layer_sizes': 3, 'learning_rate': 'adaptive'}\n",
      "0.34073820915926173 {'activation': 'relu', 'alpha': 0.03, 'hidden_layer_sizes': 3, 'learning_rate': 'constant'}\n"
     ]
    }
   ],
   "source": [
    "# Nerual Network\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "mlp_nb_clf = MLPClassifier(solver='lbfgs')\n",
    "\n",
    "param_grid = [\n",
    "    {\n",
    "#         \"solver\": ['lbfgs'],\n",
    "        \"alpha\":[0.03, 0.1, 0.3, 1.0],\n",
    "        \"learning_rate\": ['constant', 'invscaling', 'adaptive'],\n",
    "        \"activation\": ['logistic', 'relu'],\n",
    "        \"hidden_layer_sizes\": [3, 10, 30],\n",
    "    },\n",
    "]\n",
    "grid_search = GridSearchCV(mlp_nb_clf, param_grid, cv=3, scoring=\"f1\", return_train_score=True, n_jobs=3)\n",
    "grid_search.fit(x_train_prepared, y_train)\n",
    "cvres = grid_search.cv_results_\n",
    "for mean_score, params in sorted(zip(cvres['mean_test_score'], cvres['params']), key=lambda x: x[0], reverse=True):\n",
    "    print(mean_score, params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Support Vector Machine\n",
    "from sklearn.svm import SVC\n",
    "svc_clf = SVC()\n",
    "\n",
    "param_grid = [\n",
    "    {\n",
    "        \"C\": [0.03, 0.1, 0.3, 1.0],\n",
    "        \"kernel\": ['linear', 'poly', 'rbf', 'sigmoid'],\n",
    "        \"probability\": [True, False],\n",
    "        \"shrinking\": [True, False],\n",
    "    },\n",
    "]\n",
    "grid_search = GridSearchCV(svc_clf, param_grid, cv=3, scoring=\"f1\", return_train_score=True, n_jobs=3)\n",
    "grid_search.fit(x_train_prepared, y_train)\n",
    "cvres = grid_search.cv_results_\n",
    "for mean_score, params in sorted(zip(cvres['mean_test_score'], cvres['params']), key=lambda x: x[0], reverse=True):\n",
    "    print(mean_score, params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
